### 量化 (Release soon)
模型量化可将浮点FP32模型量化到整型INT8模型，实现降低模型存储及内存使用，配合Aidget推理引擎实现加速推理。

#### 离线校准量化
当前支持在模型转换过程进行，通过校准数据进行校准实现量化。
